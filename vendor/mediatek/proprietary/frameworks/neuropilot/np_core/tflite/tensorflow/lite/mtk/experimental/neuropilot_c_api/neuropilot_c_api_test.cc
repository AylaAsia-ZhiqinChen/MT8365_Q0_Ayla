/* Copyright Statement:
 *
 * This software/firmware and related documentation ("MediaTek Software") are
 * protected under relevant copyright laws. The information contained herein
 * is confidential and proprietary to MediaTek Inc. and/or its licensors.
 * Without the prior written permission of MediaTek inc. and/or its licensors,
 * any reproduction, modification, use or disclosure of MediaTek Software,
 * and information contained herein, in whole or in part, shall be strictly prohibited.
 */
/* MediaTek Inc. (C) 2019. All rights reserved.
 *
 * BY OPENING THIS FILE, RECEIVER HEREBY UNEQUIVOCALLY ACKNOWLEDGES AND AGREES
 * THAT THE SOFTWARE/FIRMWARE AND ITS DOCUMENTATIONS ("MEDIATEK SOFTWARE")
 * RECEIVED FROM MEDIATEK AND/OR ITS REPRESENTATIVES ARE PROVIDED TO RECEIVER ON
 * AN "AS-IS" BASIS ONLY. MEDIATEK EXPRESSLY DISCLAIMS ANY AND ALL WARRANTIES,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE IMPLIED WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE OR NONINFRINGEMENT.
 * NEITHER DOES MEDIATEK PROVIDE ANY WARRANTY WHATSOEVER WITH RESPECT TO THE
 * SOFTWARE OF ANY THIRD PARTY WHICH MAY BE USED BY, INCORPORATED IN, OR
 * SUPPLIED WITH THE MEDIATEK SOFTWARE, AND RECEIVER AGREES TO LOOK ONLY TO SUCH
 * THIRD PARTY FOR ANY WARRANTY CLAIM RELATING THERETO. RECEIVER EXPRESSLY ACKNOWLEDGES
 * THAT IT IS RECEIVER'S SOLE RESPONSIBILITY TO OBTAIN FROM ANY THIRD PARTY ALL PROPER LICENSES
 * CONTAINED IN MEDIATEK SOFTWARE. MEDIATEK SHALL ALSO NOT BE RESPONSIBLE FOR ANY MEDIATEK
 * SOFTWARE RELEASES MADE TO RECEIVER'S SPECIFICATION OR TO CONFORM TO A PARTICULAR
 * STANDARD OR OPEN FORUM. RECEIVER'S SOLE AND EXCLUSIVE REMEDY AND MEDIATEK'S ENTIRE AND
 * CUMULATIVE LIABILITY WITH RESPECT TO THE MEDIATEK SOFTWARE RELEASED HEREUNDER WILL BE,
 * AT MEDIATEK'S OPTION, TO REVISE OR REPLACE THE MEDIATEK SOFTWARE AT ISSUE,
 * OR REFUND ANY SOFTWARE LICENSE FEES OR SERVICE CHARGE PAID BY RECEIVER TO
 * MEDIATEK FOR SUCH MEDIATEK SOFTWARE AT ISSUE.
 *
 * The following software/firmware and/or related documentation ("MediaTek Software")
 * have been modified by MediaTek Inc. All revisions are subject to any receiver's
 * applicable license agreements with MediaTek Inc.
 */

#include "tensorflow/lite/nnapi/NeuralNetworksShim.h"
#include "tensorflow/lite/mtk/experimental/neuropilot_c_api/NeuroPilotTFLiteShim.h"
#include "gtest/gtest.h"
#include "flatbuffers/flexbuffers.h"

using namespace std;

#include <cstdlib>
#include <fstream>
#include <iostream>
#include <stdlib.h>

// Float model with single AvgPool OP
// Input [10, 784]
// Output [10, 14, 14, 1]
typedef struct {
    int width;
    int height;
} PaddingValues;

typedef struct {
    int stride_width;
    int stride_height;
    int filter_width;
    int filter_height;
    bool pad_same;  // true: SAME, false:VALID
    PaddingValues padding_values;
} CustomMaxPoolParams;

static constexpr int kInputRank = 2;
static constexpr int kInputDims[kInputRank] = {10, 784};
static constexpr size_t kInputSize = (10 * 784 * sizeof(float));
static constexpr int kOutputRank = 4;
static constexpr int kOutputDims[kOutputRank] = {10, 14, 14, 1};
static constexpr size_t kOutputSize = (10 * 14 * 14 * 1 * sizeof(float));
static constexpr char kAvgPoolModel[] = {
  0x18, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x0e, 0x00, 0x18,
  0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00,
  0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x54, 0x01, 0x00, 0x00, 0x0c, 0x00, 0x00,
  0x00, 0x10, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,
  0x68, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x54, 0x4f, 0x43, 0x4f, 0x20,
  0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x05, 0x00,
  0x00, 0x00, 0x3c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00,
  0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x8c, 0xfd, 0xff, 0xff,
  0x90, 0xfd, 0xff, 0xff, 0x94, 0xfd, 0xff, 0xff, 0x1e, 0xff, 0xff, 0xff, 0x04,
  0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x1c, 0x00,
  0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xb4, 0xfd, 0xff,
  0xff, 0x0c, 0x00, 0x14, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00,
  0x0c, 0x00, 0x00, 0x00, 0x0c, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0xf4,
  0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x70, 0x00,
  0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x14, 0x00, 0x00,
  0x00, 0x08, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x10, 0x00, 0x0e, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x00, 0x05, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x24,
  0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00,
  0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x16, 0x00, 0x00,
  0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0e, 0x00, 0x00, 0x00,
  0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x02,
  0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00, 0x0c, 0x00,
  0x10, 0x00, 0x07, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
  0x11, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,
  0x20, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,
  0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,
  0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00,
  0x00, 0x04, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x1c, 0x00, 0x00, 0x00,
  0x1c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x10,
  0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x00, 0x00, 0x06, 0x00, 0x06, 0x00,
  0x05, 0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x01, 0x06, 0x00, 0x08, 0x00, 0x07,
  0x00, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x16, 0x01, 0x00, 0x00, 0x00,
  0x03, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04,
  0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x60, 0x00, 0x00, 0x00, 0xec, 0x00,
  0x00, 0x00, 0xa0, 0x00, 0x00, 0x00, 0x72, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00,
  0x00, 0x04, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00,
  0x02, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x10, 0x03, 0x00, 0x00, 0x0b,
  0x00, 0x00, 0x00, 0x50, 0x6c, 0x61, 0x63, 0x65, 0x68, 0x6f, 0x6c, 0x64, 0x65,
  0x72, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x08, 0x00, 0x00,
  0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x7f, 0x43, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc6,
  0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x1c, 0x00,
  0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00,
  0x00, 0x1c, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,
  0x07, 0x00, 0x00, 0x00, 0x52, 0x65, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0xbc,
  0xff, 0xff, 0xff, 0x00, 0x00, 0x0e, 0x00, 0x14, 0x00, 0x04, 0x00, 0x00, 0x00,
  0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00,
  0x00, 0x02, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00,
  0x04, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x0e,
  0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x79, 0x73,
  0x00, 0x00, 0x04, 0x00, 0x06, 0x00, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e,
  0x00, 0x18, 0x00, 0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,
  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x10, 0x00, 0x00, 0x00, 0x01,
  0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x01, 0x00,
  0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x52, 0x65, 0x73,
  0x68, 0x61, 0x70, 0x65, 0x2f, 0x73, 0x68, 0x61, 0x70, 0x65, 0x00, 0x00, 0x00,
  0x04, 0x00, 0x04, 0x00, 0x04, 0x00, 0x00, 0x00
};

TEST(TFLiteCApiTest, NullInstance) {
  const char* model_path = "/data/local/tmp/model_test.lite";
  int ret = ANeuroPilotTFLiteWrapper_makeTFLite(nullptr, model_path);
  ASSERT_EQ(ANEURALNETWORKS_UNEXPECTED_NULL, ret);
}

TEST(TFLiteCApiTest, NullModelPath) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret = ANeuroPilotTFLiteWrapper_makeTFLite(&tflite, nullptr);
  ASSERT_EQ(ANEURALNETWORKS_UNEXPECTED_NULL, ret);
}

TEST(TFLiteCApiTest, CreateNonExistentModel) {
  // Try to load a non-existent model.
  const char* model_path = "/data/local/tmp/model_test.lite";
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret = ANeuroPilotTFLiteWrapper_makeTFLite(&tflite, model_path);
  ANeuroPilotTFLiteWrapper_free(tflite);
  ASSERT_EQ(ANEURALNETWORKS_BAD_DATA, ret);
}

TEST(TFLiteCApiTest, CreateWithBuffer) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret =
      ANeuroPilotTFLiteWrapper_makeTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel));
  ANeuroPilotTFLiteWrapper_free(tflite);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
}

TEST(TFLiteCApiTest, Create) {
  remove("/data/local/tmp/model.lite");
  std::ofstream tflite_file("/data/local/tmp/model.lite",
    std::ios::out | std::ios::app | std::ios::binary);
  ASSERT_TRUE(tflite_file.is_open());

  tflite_file.write(kAvgPoolModel, sizeof(kAvgPoolModel));
  tflite_file.close();

  ANeuralNetworksTFLite* tflite = nullptr;
  int ret = ANeuroPilotTFLiteWrapper_makeTFLite(&tflite,
                                                "/data/local/tmp/model.lite");
  ANeuroPilotTFLiteWrapper_free(tflite);

  remove("/data/local/tmp/model.lite");
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
}

TEST(TFLiteCApiTest, GetTensorCount) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret =
      ANeuroPilotTFLiteWrapper_makeTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel));
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  int32_t count = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorCount(tflite,
                                                TFLITE_BUFFER_TYPE_INPUT,
                                                &count);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(count, 1);
  ret = ANeuroPilotTFLiteWrapper_getTensorCount(tflite,
                                                TFLITE_BUFFER_TYPE_OUTPUT,
                                                &count);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(count, 1);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, GetInputTensor) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret =
      ANeuroPilotTFLiteWrapper_makeTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel));
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  int rank = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorRank(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    &rank);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(rank, kInputRank);
  int diemssions[rank];
  ret = ANeuroPilotTFLiteWrapper_getTensorDimensions(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    diemssions);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  for (auto i = 0; i < rank; i++) {
    ASSERT_EQ(kInputDims[i], diemssions[i]);
  }
  size_t buffer_size = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorByteSize(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    &buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(kInputSize, buffer_size);
  TFLiteTensorType tensr_type = TFLITE_TENSOR_TYPE_NONE;
  ret = ANeuroPilotTFLiteWrapper_getTensorType(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    &tensr_type);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(TFLITE_TENSOR_TYPE_FLOAT, tensr_type);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, GetOutputTensor) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret =
      ANeuroPilotTFLiteWrapper_makeTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel));
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  int rank = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorRank(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    &rank);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(rank, kOutputRank);
  int diemssions[rank];
  ret = ANeuroPilotTFLiteWrapper_getTensorDimensions(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    diemssions);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  for (auto i = 0; i < rank; i++) {
    ASSERT_EQ(kOutputDims[i], diemssions[i]);
  }
  size_t buffer_size = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorByteSize(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    &buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(kOutputSize, buffer_size);
  TFLiteTensorType tensr_type = TFLITE_TENSOR_TYPE_NONE;
  ret = ANeuroPilotTFLiteWrapper_getTensorType(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    &tensr_type);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(TFLITE_TENSOR_TYPE_FLOAT, tensr_type);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, Invoke) {
  ANeuralNetworksTFLite* tflite = nullptr;
  int ret =
      ANeuroPilotTFLiteWrapper_makeTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel));
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  size_t in_buffer_size = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorByteSize(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    &in_buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  void* input_buffer = reinterpret_cast<void*>(calloc(1, in_buffer_size));
  float* p = reinterpret_cast<float*>(input_buffer);
  for (auto i = 0; i < in_buffer_size / sizeof(float); i++) {
    *p = rand() % 256;
    p++;
  }
  ret = ANeuroPilotTFLiteWrapper_setInputTensorData(tflite,
                                                    0,
                                                    input_buffer,
                                                    in_buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuroPilotTFLiteWrapper_invoke(tflite);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  int rank = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorRank(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    &rank);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(rank, kOutputRank);

  int diemssions[rank];
  ret = ANeuroPilotTFLiteWrapper_getTensorDimensions(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    diemssions);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  size_t out_buffer_size = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorByteSize(tflite,
                                    TFLITE_BUFFER_TYPE_OUTPUT,
                                    0,
                                    &out_buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  void* output_buffer = reinterpret_cast<void*>(calloc(1, out_buffer_size));
  ASSERT_NE(output_buffer, nullptr);
  ret = ANeuroPilotTFLiteWrapper_getOutputTensorData(tflite,
                                                     0,
                                                     output_buffer,
                                                     out_buffer_size);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  if (input_buffer != nullptr) {
    free(input_buffer);
  }
  if (output_buffer != nullptr) {
    free(output_buffer);
  }

  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, ResizeInputTensor) {
  ANeuralNetworksTFLite* tflite = nullptr;
  ANeuralNetworksTFLiteOptions* options = nullptr;
  int ret = ANeuralNetworksTFLiteOptions_create(&options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  static constexpr int dims[kInputRank] = {8, 784};
  ret = ANeuralNetworksTFLiteOptions_resizeInputTensor(options,
                                                      0,
                                                      dims,
                                                      kInputRank);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ret = ANeuroPilotTFLiteWrapper_makeAdvTFLiteWithBuffer(&tflite,
                                                    kAvgPoolModel,
                                                    sizeof(kAvgPoolModel),
                                                    options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  int rank = 0;
  ret = ANeuroPilotTFLiteWrapper_getTensorRank(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    &rank);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  ASSERT_EQ(rank, kInputRank);
  int diemssions[rank];
  ret = ANeuroPilotTFLiteWrapper_getTensorDimensions(tflite,
                                    TFLITE_BUFFER_TYPE_INPUT,
                                    0,
                                    diemssions);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
  for (auto i = 0; i < rank; i++) {
    ASSERT_EQ(dims[i], diemssions[i]);
  }
  ANeuralNetworksTFLiteOptions_free(options);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, AccelerationModeCpu) {
  ANeuralNetworksTFLite* tflite = nullptr;
  ANeuralNetworksTFLiteOptions* options = nullptr;
  int ret = ANeuralNetworksTFLiteOptions_create(&options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuralNetworksTFLiteOptions_setAccelerationMode(options,
                                                         NP_ACCELERATION_CPU);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuroPilotTFLiteWrapper_makeAdvTFLiteWithBuffer(
      &tflite, kAvgPoolModel, sizeof(kAvgPoolModel), options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuroPilotTFLiteWrapper_invoke(tflite);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ANeuralNetworksTFLiteOptions_free(options);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, AccelerationModeNNAPI) {
  ANeuralNetworksTFLite* tflite = nullptr;
  ANeuralNetworksTFLiteOptions* options = nullptr;
  int ret = ANeuralNetworksTFLiteOptions_create(&options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuralNetworksTFLiteOptions_setAccelerationMode(options,
                                                         NP_ACCELERATION_NNAPI);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuroPilotTFLiteWrapper_makeAdvTFLiteWithBuffer(
      &tflite, kAvgPoolModel, sizeof(kAvgPoolModel), options);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ret = ANeuroPilotTFLiteWrapper_invoke(tflite);
  ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);

  ANeuralNetworksTFLiteOptions_free(options);
  ANeuroPilotTFLiteWrapper_free(tflite);
}

static const char custom_max_pool_quant_model[] = {
    0x18, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x20
    , 0x02, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x54, 0x4f, 0x43, 0x4f, 0x20
    , 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x03, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0xf8, 0xff, 0xff, 0xff, 0xfc
    , 0xff, 0xff, 0xff, 0x04, 0x00, 0x04, 0x00, 0x04, 0x00, 0x00, 0x00, 0x18, 0xff, 0xff, 0xff, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x1c, 0x01, 0x00, 0x00, 0x01
    , 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x90, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x86, 0xff, 0xff, 0xff, 0x00
    , 0x00, 0x00, 0x03, 0x10, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x0a
    , 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x50, 0x6c, 0x61, 0x63, 0x65, 0x68, 0x6f, 0x6c, 0x64, 0x65, 0x72, 0x00, 0x84, 0xff, 0xff, 0xff, 0x30, 0x00, 0x00, 0x00, 0x24
    , 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00
    , 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x7f, 0x43, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x10
    , 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0d
    , 0x00, 0x00, 0x00, 0x43, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x14, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0c
    , 0x00, 0x00, 0x00, 0x2c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01
    , 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x3f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x7f, 0x43, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x14
    , 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c
    , 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x60, 0x00, 0x00, 0x00, 0x6b
    , 0x73, 0x69, 0x7a, 0x65, 0x00, 0x04, 0x01, 0x02, 0x02, 0x01, 0x70, 0x61, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x00, 0x04, 0x53, 0x41, 0x4d, 0x45, 0x00, 0x5f, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x5f
    , 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x64, 0x00, 0x73, 0x74, 0x72, 0x69, 0x64, 0x65, 0x73, 0x00, 0x04, 0x01, 0x02, 0x02, 0x01, 0x64, 0x61, 0x74, 0x61, 0x5f, 0x66, 0x6f, 0x72, 0x6d
    , 0x61, 0x74, 0x00, 0x04, 0x4e, 0x48, 0x57, 0x43, 0x00, 0x05, 0x32, 0x14, 0x4d, 0x43, 0x24, 0x05, 0x01, 0x05, 0x01, 0x0f, 0x4e, 0x42, 0x23, 0x68, 0x14, 0x2c, 0x14, 0x2c, 0x0a, 0x24, 0x01, 0x01
    , 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x08, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20, 0x04, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x43
    , 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00, 0x00
};

static const char custom_max_pool_model[] = {
    0x18, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0xd0
    , 0x01, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x54, 0x4f, 0x43, 0x4f, 0x20
    , 0x43, 0x6f, 0x6e, 0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x03, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x20, 0xff, 0xff, 0xff, 0x24
    , 0xff, 0xff, 0xff, 0x28, 0xff, 0xff, 0xff, 0x0c, 0x00, 0x14, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x08
    , 0x00, 0x00, 0x00, 0xc0, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x74, 0x00, 0x00, 0x00, 0x04
    , 0x00, 0x00, 0x00, 0xa2, 0xff, 0xff, 0xff, 0x10, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0a
    , 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x50, 0x6c, 0x61, 0x63, 0x65, 0x68, 0x6f, 0x6c, 0x64, 0x65, 0x72, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x04
    , 0x00, 0x08, 0x00, 0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x7f, 0x43, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
    , 0x00, 0x0e, 0x00, 0x14, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x20
    , 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x43, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x04, 0x00, 0x04
    , 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x14, 0x00, 0x14, 0x00, 0x00, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x14
    , 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x1c, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00
    , 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x61, 0x00, 0x00, 0x00, 0x6b, 0x73, 0x69, 0x7a, 0x65, 0x00, 0x04, 0x01, 0x02, 0x02, 0x01, 0x70, 0x61, 0x64, 0x64, 0x69, 0x6e, 0x67, 0x00, 0x05, 0x56
    , 0x41, 0x4c, 0x49, 0x44, 0x00, 0x5f, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x5f, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65, 0x64, 0x00, 0x73, 0x74, 0x72, 0x69, 0x64, 0x65, 0x73, 0x00, 0x04
    , 0x01, 0x02, 0x02, 0x01, 0x64, 0x61, 0x74, 0x61, 0x5f, 0x66, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x00, 0x04, 0x4e, 0x48, 0x57, 0x43, 0x00, 0x05, 0x32, 0x14, 0x4e, 0x44, 0x24, 0x05, 0x01, 0x05, 0x01
    , 0x0f, 0x4f, 0x43, 0x23, 0x68, 0x14, 0x2c, 0x14, 0x2c, 0x0a, 0x24, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x07, 0x00, 0x08, 0x00, 0x08
    , 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20, 0x04, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00, 0x43, 0x75, 0x73, 0x74, 0x6f, 0x6d, 0x4d, 0x61, 0x78, 0x50, 0x6f, 0x6f, 0x6c, 0x00, 0x00, 0x00
};

static int computePadding(int stride, int dilation_rate, int in_size,
                          int filter_size, int out_size) {
    int effective_filter_size = (filter_size - 1) * dilation_rate + 1;
    int padding = ((out_size - 1) * stride + effective_filter_size - in_size) / 2;
    return padding > 0 ? padding : 0;
}

static void* initCustomMaxPool(TfLiteContext* context, const char* buffer,
                               size_t length) {
    (void)context;
    CustomMaxPoolParams* user_data = new CustomMaxPoolParams;
    auto map = flexbuffers::GetRoot((const uint8_t*)buffer, length).AsMap();
    cout << "kernel type: " << map["ksize"].GetType() << endl;
    cout << "strides type: " << map["strides"].GetType() << endl;
    cout << "padding type: " << map["padding"].GetType() << endl;
    auto kernel_vec = map["ksize"].AsTypedVector();
    auto strides_vec = map["strides"].AsTypedVector();
    cout << "kernel size: " << kernel_vec.size() << endl;
    cout << "stride size: " << strides_vec.size() << endl;

    user_data->filter_width = kernel_vec[2].AsInt8();
    user_data->filter_height = kernel_vec[1].AsInt8();
    user_data->stride_width = strides_vec[2].AsInt8();
    user_data->stride_height = strides_vec[1].AsInt8();
    string string_pad_same("SAME");
    user_data->pad_same = map["padding"].ToString().compare(
                                          string_pad_same) == 0 ? true : false;
    cout << "pad_same: " << user_data->pad_same << endl;
    cout << "filter_width: " << user_data->filter_width << endl;
    cout << "filter_height: " << user_data->filter_height << endl;
    cout << "stride_width: " << user_data->stride_width << endl;
    cout << "stride_height: " << user_data->stride_height << endl;

    return user_data;
}

static void freeCustomMaxPool(TfLiteContext* context, void* buffer) {
    (void)context;
    // Free the CustomMaxPoolParams buffer allocated in initCustomMaxPool()
    delete reinterpret_cast<CustomMaxPoolParams*>(buffer);
}

static TfLiteStatus prepareCustomMaxPool(TfLiteContext* context,
        TfLiteNode* node) {
    CustomMaxPoolParams* user_data =
                    reinterpret_cast<CustomMaxPoolParams*>
                    (ANeuroPilotTFLiteWrapper_getCustomOpUserData(node));

    TFLiteTensorExt input;

    if (ANeuroPilotTFLiteWrapper_getCustomOpInput(context, node, 0,
            &input) != ANEURALNETWORKS_NO_ERROR) {
        cout << "Can not get input tensor" << endl;
        return kTfLiteError;
    }

    if (input.dimsSize != 4) {
        cout << "Wrong input dimension:" << input.dimsSize << "!= 4" << endl;
        return kTfLiteError;
    }

    int batches = input.dims[0];
    int height = input.dims[1];
    int width = input.dims[2];
    int channels_out = input.dims[3];

    auto pad_same = user_data->pad_same;
    auto computeOutSize = [pad_same](int imageSize, int filterSize,
    int stride) -> int {
        return pad_same == true
        ? (imageSize + stride - 1) / stride
        : pad_same == false
        ? (imageSize - filterSize + stride) / stride
        : 0;
    };

    int outWidth = computeOutSize(width, user_data->filter_width,
                                  user_data->stride_width);
    int outHeight = computeOutSize(height, user_data->filter_height,
                                   user_data->stride_height);

    user_data->padding_values.height = computePadding(user_data->stride_height, 1,
                                       height,
                                       user_data->filter_height, outHeight);
    user_data->padding_values.width = computePadding(user_data->stride_width, 1,
                                      width,
                                      user_data->filter_width, outWidth);

    // Prepare the output dimension according to the input and max_disp attribute.
    TfLiteIntArray* outputSize = ANeuroPilotTFLiteWrapper_createIntArray(4);
    outputSize->data[0] = batches;
    outputSize->data[1] = outHeight;
    outputSize->data[2] = outWidth;
    outputSize->data[3] = channels_out;

    // Resize the output dimension
    int ret = ANeuroPilotTFLiteWrapper_resizeCustomOpOutput(context, node, 0,
              outputSize);
    return (ret == ANEURALNETWORKS_NO_ERROR ? kTfLiteOk : kTfLiteError);
}

static TfLiteStatus addCustomMaxPoolParams(void* data,
        ANeuralNetworksModel* nn_model,
        vector<uint32_t>& augmented_inputs, uint32_t& next_id) {
    CustomMaxPoolParams* user_data =
                    reinterpret_cast<CustomMaxPoolParams*>(data);

    auto add_scalar_int32 = [&nn_model, &augmented_inputs,
               &next_id](int value) {
        ANeuralNetworksOperandType operand_type{.type = ANEURALNETWORKS_INT32};

        if (ANeuralNetworksModel_addOperand(nn_model,
                                            &operand_type) != ANEURALNETWORKS_NO_ERROR) {
            cout << "Fail to add operand to NN" << endl;
        }

        if (ANeuralNetworksModel_setOperandValue(nn_model, next_id, &value,
                sizeof(int32_t)) != ANEURALNETWORKS_NO_ERROR) {
            cout << "Fail to set operand value to NN" << endl;
        }

        augmented_inputs.push_back(next_id++);
    };
    cout << "addCustomMaxPoolParams()" << endl;
    add_scalar_int32(user_data->pad_same == true ? ANEURALNETWORKS_PADDING_SAME :
                     ANEURALNETWORKS_PADDING_VALID);
    add_scalar_int32(user_data->stride_width);
    add_scalar_int32(user_data->stride_height);
    add_scalar_int32(user_data->filter_width);
    add_scalar_int32(user_data->filter_height);
    add_scalar_int32(ANEURALNETWORKS_FUSED_NONE);
    return kTfLiteOk;
}

TEST(TFLiteCApiTest, CreateCustomWithBuffer) {
    const vector<TFLiteCustomOpExt> customOperations = {
        {
            .op_name = "CustomMaxPool",
            .target_name = "gpu",
            .vendor_name = "mtk",
            .init = initCustomMaxPool,
            .free = freeCustomMaxPool,
            .prepare = prepareCustomMaxPool,
            .add_params = addCustomMaxPoolParams,
        },
    };
    ANeuralNetworksTFLite* tflite = nullptr;
    int ret = ANeuroPilotTFLiteWrapper_makeCustomTFLiteWithBuffer(&tflite,
              custom_max_pool_model,
              sizeof(custom_max_pool_model), customOperations);
    ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
    if (ret == ANEURALNETWORKS_NO_ERROR) {
        ret = ANeuroPilotTFLiteWrapper_invoke(tflite);
    }
    ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
    ANeuroPilotTFLiteWrapper_free(tflite);
}

TEST(TFLiteCApiTest, CreateCustomWithQuantBuffer) {
    const vector<TFLiteCustomOpExt> customOperations = {
        {
            .op_name = "CustomMaxPool",
            .target_name = "vpu",
            .vendor_name = "mtk",
            .init = initCustomMaxPool,
            .free = freeCustomMaxPool,
            .prepare = prepareCustomMaxPool,
            .add_params = addCustomMaxPoolParams,
        },
    };
    ANeuralNetworksTFLite* tflite = nullptr;
    int ret = ANeuroPilotTFLiteWrapper_makeCustomTFLiteWithBuffer(&tflite,
              custom_max_pool_quant_model,
              sizeof(custom_max_pool_quant_model), customOperations);
    ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
    if (ret == ANEURALNETWORKS_NO_ERROR) {
        ret = ANeuroPilotTFLiteWrapper_invoke(tflite);
    }
    ASSERT_EQ(ANEURALNETWORKS_NO_ERROR, ret);
    ANeuroPilotTFLiteWrapper_free(tflite);
}

int main(int argc, char** argv) {
  testing::InitGoogleTest(&argc, argv);
  int ret = RUN_ALL_TESTS();
  return ret;
}
